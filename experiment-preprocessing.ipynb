{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncd {TARGETDIR}\\nfind {MIDIFILEDIR} \\\\( -name \"bach*.mid\" -o -name \"beethoven*.mid\" -o -name \"scarlatti*.mid\" \\\\) -type f -exec cp {} . \\\\;\\nfind . -type f -name \"*.mid\" -exec /Applications/MuseScore\\\\ 2.app/Contents/MacOS/mscore {} --export-to {}.mxl \\\\;\\nfor f in *.mxl; do mv \"$f\" \"${f%.mid.mxl}.mxl\"; done\\nls *.mxl > mxl_list.txt\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################\n",
    "# Preprocessing #\n",
    "#################\n",
    "# Scores by other composers from the Bach family have been removed beforehand. \n",
    "# Miscellaneous scores like mass pieces have also been removed; the assumption here is that\n",
    "# since different interpretations of the same piece (e.g. Ave Maria, etc) exist, including\n",
    "# theses pieces might hurt the prediction accuracy, here mostly based on chord progression. \n",
    "# (more exactly, a reduced version of the chord progression.)\n",
    "\n",
    "# In shell, find and copy midi files to target data directory and convert to mxl:\n",
    "'''\n",
    "cd {TARGETDIR}\n",
    "find {MIDIFILEDIR} \\( -name \"bach*.mid\" -o -name \"beethoven*.mid\" -o -name \"scarlatti*.mid\" \\) -type f -exec cp {} . \\;\n",
    "find . -type f -name \"*.mid\" -exec /Applications/MuseScore\\ 2.app/Contents/MacOS/mscore {} --export-to {}.mxl \\;\n",
    "for f in *.mxl; do mv \"$f\" \"${f%.mid.mxl}.mxl\"; done\n",
    "ls *.mxl > mxl_list.txt\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "from os import listdir\n",
    "from os.path import isfile, getsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# timeout function that lets move on beyond too big files.\n",
    "# by Thomas Ahle: http://stackoverflow.com/a/22348885\n",
    "import signal\n",
    "\n",
    "class timeout:\n",
    "    def __init__(self, seconds=1, error_message='Timeout'):\n",
    "        self.seconds = seconds\n",
    "        self.error_message = error_message\n",
    "    def handle_timeout(self, signum, frame):\n",
    "        raise TimeoutError(self.error_message)\n",
    "    def __enter__(self):\n",
    "        signal.signal(signal.SIGALRM, self.handle_timeout)\n",
    "        signal.alarm(self.seconds)\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        signal.alarm(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(mxllist, composer):\n",
    "    composer_list = [f for f in mxllist if f.replace('-', '_').split('_')[0] == composer]\n",
    "    for file in composer_list:\n",
    "        if (getsize(file)>10000): # remove too short scores that may contain no notes\n",
    "            with timeout(seconds=6000):\n",
    "                try:\n",
    "                    s = converter.parse(mxldir+file)\n",
    "                    try:\n",
    "                        k = s.flat.keySignature.sharps\n",
    "                    except AttributeError:\n",
    "                        k = s.analyze('key').sharps\n",
    "                    except:\n",
    "                        with open('{}-parsed.txt'.format(composer), 'a') as output_file:            \n",
    "                            output_file.write('key could not by analyzed\\n')\n",
    "                        with open('{}-transposed.txt'.format(composer), 'a') as output_file:            \n",
    "                            output_file.write('key could not by analyzed\\n')\n",
    "                        continue\n",
    "                    t = s.transpose((k*5)%12)\n",
    "                except:\n",
    "                    with open('{}-parsed.txt'.format(composer), 'a') as output_file:\n",
    "                        output_file.write('timeout\\n')\n",
    "                    with open('{}-transposed.txt'.format(composer), 'a') as output_file:            \n",
    "                        output_file.write('timeout\\n')\n",
    "                    continue\n",
    "\n",
    "            fp_s = converter.freeze(s, fmt='pickle')\n",
    "            fp_t = converter.freeze(t, fmt='pickle')\n",
    "\n",
    "            with open('{}-parsed.txt'.format(composer), 'a') as output_file:\n",
    "                output_file.write(fp_s+'\\n')\n",
    "            with open('{}-transposed.txt'.format(composer), 'a') as output_file:            \n",
    "                output_file.write(fp_t+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('mxl_list.txt', 'r') as f:\n",
    "    mxllist = [line.strip() for line in f.readlines()]\n",
    "\n",
    "parse(mxllist, 'bach')\n",
    "parse(mxllist, 'beethoven')\n",
    "parse(mxllist, 'debussy')\n",
    "parse(mxllist, 'scarlatti')\n",
    "parse(mxllist, 'victoria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################\n",
    "# Feature Extraction #\n",
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist] # by Alex Martinelli & Guillaume Jacquenot: http://stackoverflow.com/a/952952\n",
    "uniqify = lambda seq: list(set(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define known chords\n",
    "major, minor, suspended, augmented, diminished, major_sixth, minor_sixth, dominant_seventh, major_seventh, minor_seventh, half_diminished_seventh, diminished_seventh, major_ninth, dominant_ninth, dominant_minor_ninth, minor_ninth = [0,4,7],[0,3,7],[0,5,7],[0,4,8],[0,3,6],[0,4,7,9],[0,3,7,9],[0,4,7,10],[0,4,7,11],[0,3,7,10],[0,3,6,10],[0,3,6,9],[0,2,4,7,11],[0,2,4,7,10],[0,1,4,7,10],[0,2,3,7,10]\n",
    "chord_types_list = [major, minor, suspended, augmented, diminished, major_sixth, minor_sixth, dominant_seventh, major_seventh, minor_seventh, half_diminished_seventh, diminished_seventh, major_ninth, dominant_ninth, dominant_minor_ninth, minor_ninth]\n",
    "chord_types_string = ['major', 'minor', 'suspended', 'augmented', 'diminished', 'major_sixth', 'minor_sixth', 'dominant_seventh', 'major_seventh', 'minor_seventh', 'half_diminished_seventh', 'diminished_seventh', 'major_ninth', 'dominant_ninth', 'dominant_minor_ninth', 'minor_ninth']\n",
    "\n",
    "roots = list(range(12))\n",
    "chord_orders = flatten([[{(n+r)%12 for n in v} for v in chord_types_list] for r in roots])\n",
    "unique_orders = []\n",
    "for i in range(192):\n",
    "    if chord_orders[i] not in unique_orders:\n",
    "        unique_orders.append(chord_orders[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_chords(s):\n",
    "    sf = s.flat\n",
    "    chords_by_offset = []\n",
    "    for i in range(int(sf.highestTime)):\n",
    "        chords_by_offset.append(chord.Chord(sf.getElementsByOffset(i,i+1, includeEndBoundary=False, mustFinishInSpan=False, mustBeginInSpan=False).notes))\n",
    "    return chords_by_offset\n",
    "\n",
    "def find_neighbor_note(n, k):\n",
    "    # find notes k steps away from n\n",
    "    return (roots[n-6:]+roots[:(n+6)%12])[6+k], (roots[n-6:]+roots[:(n+6)%12])[6-k]\n",
    "\n",
    "def find_note_distance(n1, n2):\n",
    "    return abs(6 - (roots[n1-6:]+roots[:(n1+6)%12]).index(n2))\n",
    "\n",
    "def find_chord_distance(set1, set2):\n",
    "    d1, d2 = set1.difference(set2), set2.difference(set1)\n",
    "    if len(d1) < len(d2):\n",
    "        longer, shorter = d2, list(d1)\n",
    "    else:\n",
    "        longer, shorter = d1, list(d2)\n",
    "    distances = []\n",
    "    for combination in itertools.combinations(longer, len(shorter)):\n",
    "        for permutation in itertools.permutations(combination):\n",
    "            dist_p = abs(len(d1)-len(d2))*3 # length difference means notes need to be added/deleted. weighted by 3\n",
    "            for i in range(len(shorter)):\n",
    "                dist_p += find_note_distance(shorter[i], permutation[i])\n",
    "            distances.append(dist_p)\n",
    "    return min(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CACHE = dict()\n",
    "\n",
    "def find_closest_chord(c, cache=CACHE):\n",
    "    if len(c) == 0:\n",
    "        return -1 # use -1 for rest (chords are 0 to 191)\n",
    "    \n",
    "    # retrieve from existing knowledge\n",
    "    o_str, o, p = str(c.normalOrder), set(c.normalOrder), c.pitchClasses\n",
    "    if o in chord_orders:\n",
    "        return chord_orders.index(o)\n",
    "        # the above root sometimes differs from c.findRoot(), which might be more reliable.\n",
    "        # however, the errors are rare and it should be good enough for now.\n",
    "    if o_str in cache.keys():\n",
    "        return cache[o_str]\n",
    "    \n",
    "    # find closest chord from scratch\n",
    "    chord_distances = dict()\n",
    "    most_common_note = Counter(c.pitchClasses).most_common(1)[0][0]\n",
    "\n",
    "    for i in range(192):\n",
    "        d = find_chord_distance(o, chord_orders[i])\n",
    "        # prioritize found chord's root note if most common note of the chord.\n",
    "        if int(i/16) == most_common_note:\n",
    "            d += -1\n",
    "        if chord_distances.get(d) == None:\n",
    "            chord_distances[d] = []\n",
    "        chord_distances[d].append(i)\n",
    "\n",
    "    # if multiple chords are tied, use first one (could be better)\n",
    "    closest_chord = chord_distances[min(chord_distances.keys())][0]\n",
    "    \n",
    "    cache[o_str] = closest_chord\n",
    "    return closest_chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(parsed_list, idx):\n",
    "    s = converter.thaw(parsed_list[idx])\n",
    "    chords_by_offset = merge_chords(s)\n",
    "\n",
    "    chord_sequence = []\n",
    "    for i in range(len(chords_by_offset)):\n",
    "        chord_sequence.append(find_closest_chord(chords_by_offset[i], CACHE))\n",
    "    return chord_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('bach-parsed.txt', 'r') as f:\n",
    "    FILES_BACH = [line.strip() for line in f.readlines()]\n",
    "with open('beethoven-parsed.txt', 'r') as f:\n",
    "    FILES_BEETHOVEN = [line.strip() for line in f.readlines()]\n",
    "with open('debussy-parsed.txt', 'r') as f:\n",
    "    FILES_DEBUSSY = [line.strip() for line in f.readlines()]\n",
    "with open('scarlatti-parsed.txt', 'r') as f:\n",
    "    FILES_SCARLATTI = [line.strip() for line in f.readlines()]\n",
    "with open('victoria-parsed.txt', 'r') as f:\n",
    "    FILES_VICTORIA = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "for i in range(len(FILES_BACH)):\n",
    "    with open('bach-chordsequence.txt', 'a') as f:\n",
    "        f.write(str(extract_features(FILES_BACH, i))+'\\n')\n",
    "for i in range(len(FILES_BEETHOVEN)):\n",
    "    with open('beethoven-chordsequence.txt', 'a') as f:\n",
    "        f.write(str(extract_features(FILES_BEETHOVEN, i))+'\\n')\n",
    "for i in range(len(FILES_DEBUSSY)):\n",
    "    with open('debussy-chordsequence.txt', 'a') as f:\n",
    "        f.write(str(extract_features(FILES_DEBUSSY, i))+'\\n')\n",
    "for i in range(len(FILES_SCARLATTI)):\n",
    "    with open('scarlatti-chordsequence.txt', 'a') as f:\n",
    "        f.write(str(extract_features(FILES_SCARLATTI, i))+'\\n')\n",
    "for i in range(len(FILES_VICTORIA)):\n",
    "    with open('victoria-chordsequence.txt', 'a') as f:\n",
    "        f.write(str(extract_features(FILES_VICTORIA, i))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Additional feature set: extract durations of notes, chords, and rests\n",
    "def find_length_add_to_list(cnr, out_list):\n",
    "    try:\n",
    "        out_list.append(cnr.duration.fullName)\n",
    "    except:\n",
    "        out_list.append(str(cnr.duration.quarterLength))\n",
    "\n",
    "def extract_cnr_duration(piece):\n",
    "    s = converter.thaw(piece).flat\n",
    "    chords, notes, rests = [], [], []\n",
    "    for c in s.getElementsByClass(chord.Chord):\n",
    "        find_length_add_to_list(c, chords)\n",
    "    for n in s.getElementsByClass(note.Note):\n",
    "        find_length_add_to_list(n, notes)\n",
    "    for r in s.getElementsByClass(note.Rest):\n",
    "        find_length_add_to_list(r, rests)\n",
    "    elements = ['chord|'+d for d in chords] + ['note|'+d for d in notes] + ['rest|'+d for d in rests]\n",
    "    return ';'.join(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for piece in FILES_BACH:\n",
    "    with open('bach-durations.txt', 'a') as f:\n",
    "        f.write(extract_cnr_duration(piece)+'\\n')\n",
    "for piece in FILES_BEETHOVEN:\n",
    "    with open('beethoven-durations.txt', 'a') as f:\n",
    "        f.write(extract_cnr_duration(piece)+'\\n')\n",
    "for piece in FILES_DEBUSSY:\n",
    "    with open('debussy-durations.txt', 'a') as f:\n",
    "        f.write(extract_cnr_duration(piece)+'\\n')\n",
    "for piece in FILES_SCARLATTI:\n",
    "    with open('scarlatti-durations.txt', 'a') as f:\n",
    "        f.write(extract_cnr_duration(piece)+'\\n')\n",
    "for piece in FILES_VICTORIA:\n",
    "    with open('victoria-durations.txt', 'a') as f:\n",
    "        f.write(extract_cnr_duration(piece)+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
